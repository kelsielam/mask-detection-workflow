{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraires for images and data\n",
    "from PIL import Image\n",
    "import re\n",
    "import glob,os\n",
    "from bs4 import BeautifulSoup\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "# libraries for deep learning\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets, models\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\n",
    "                                                                                                                                                                           \n",
    "import logging\n",
    "from Pegasus.api import *\n",
    "\n",
    "from utils.wf import split_data_filenames, create_ann_list,create_augmented_filelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# When you restart the docker make sure to reinstall these:\n",
    "! sudo python3 -m pip install --upgrade pip\n",
    "! sudo python3 -m pip install --upgrade Pillow numpy torchvision matplotlib\n",
    "! sudo python3 -m pip install pandas torch bs4\n",
    "\n",
    "! sudo pip3 install opencv-python \n",
    "! sudo pip3 install --upgrade setuptools\n",
    "! sudo pip3 install opencv-python \n",
    "! sudo pip3 install optuna==2.0.0 \n",
    "! sudo pip3 install matplotlib \n",
    "! sudo pip3 install torch\n",
    "! sudo pip3 install scikit-image\n",
    "! sudo pip3 install torchvision \n",
    "! sudo pip3 install pytorchtools\n",
    "! sudo pip3 install joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA AQUSITION\n",
    "imagesList = glob.glob('data/images/*.png')\n",
    "annotationList = glob.glob('data/annotations/*.xml')\n",
    "\n",
    "#DATA SPLIT\n",
    "train_filenames,val_filenames,test_filenames, files_split_dict = split_data_filenames(imagesList)\n",
    "\n",
    "#TODO: check the correctness of the fun\n",
    "train_imgs, train_ann = create_ann_list(train_filenames)\n",
    "val_imgs, val_ann     = create_ann_list(val_filenames)\n",
    "test_imgs, test_ann   = create_ann_list(test_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add images from group data\n",
    "rc = ReplicaCatalog()\n",
    "\n",
    "inputFiles = []\n",
    "for img in imagesList:\n",
    "    fileName = img.split(\"/\")[-1]\n",
    "    img_file = File(fileName)\n",
    "    inputFiles.append(img_file)\n",
    "    rc.add_replica(\"local\", img_file,  os.path.join(os.getcwd(),str(img)))\n",
    "    \n",
    "annFiles = []\n",
    "for ann in annotationList:\n",
    "    fileName = ann.split(\"/\")[-1]\n",
    "    ann_file = File(fileName)\n",
    "    annFiles.append(ann_file)\n",
    "    rc.add_replica(\"local\", ann_file,  os.path.join(os.getcwd(),str(ann)))\n",
    "rc.write()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Transformations\n",
    "\n",
    "dist_plot = Transformation(\n",
    "                \"dist_plot\",\n",
    "                site=\"local\",\n",
    "                pfn=  os.path.join(os.getcwd(),\"bin/plot_class_distribution.py\"),\n",
    "                is_stageable=True\n",
    "            )\n",
    "\n",
    "augment_imgs = Transformation(\n",
    "                \"augment_images\",\n",
    "                site=\"local\",\n",
    "                pfn=  os.path.join(os.getcwd(),\"bin/data_aug.py\"),\n",
    "                is_stageable=True\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tc = TransformationCatalog()\n",
    "tc.add_transformations(augment_imgs, dist_plot)#, model_hpo)\n",
    "tc.write()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Pegasus.api.workflow.Job at 0x7fc1bcdf35f8>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create workflow\n",
    "\n",
    "wf = Workflow(\"mask_detection_workflow\")\n",
    "\n",
    "train_preprocessed_files = create_augmented_filelist(train_filenames,2)\n",
    "distribution_plot_file = File(\"class_distribution.png\")\n",
    "\n",
    "\n",
    "# Add jobs to the workflow\n",
    "\n",
    "\n",
    "# DATA EXPLORATION\n",
    "# takes in all the annotationa files and creates plot with distribution of the classes\n",
    "\n",
    "distribution_plot_job = Job(dist_plot)\n",
    "distribution_plot_job.add_inputs(*train_ann, *val_ann, *test_ann)\n",
    "distribution_plot_job.add_outputs(distribution_plot_file)\n",
    "\n",
    "\n",
    "# DATA PREPROCESSING:TRAIN DATA-DATA AUGMENTATION\n",
    "# takes images and adds gaussian noise to them\n",
    "\n",
    "preprocess_train_job = Job(augment_imgs)\n",
    "preprocess_train_job.add_inputs(*train_imgs)\n",
    "preprocess_train_job.add_outputs(*train_preprocessed_files)\n",
    "\n",
    "# DATA PREPROCESSING:VAL DATA-FILE RENAMING\n",
    "#preprocess_val_job = Job(preprocess_imgs)\n",
    "#preprocess_val_job.add_inputs(*val_imgs)\n",
    "#preprocess_val_job.add_outputs(*val_preprocessed_files)\n",
    "\n",
    "# DATA PREPROCESSING:TEST DATA-FILE RENAMING\n",
    "#preprocess_test_job = Job(preprocess_imgs)\n",
    "#preprocess_test_job.add_inputs(*test_imgs)\n",
    "#preprocess_test_job.add_outputs(*test_preprocessed_files)\n",
    "\n",
    "\n",
    "# HYPERPARAMETER OPTIMIZATION\n",
    "\n",
    "# MODEL TRAINING\n",
    "\n",
    "# MODEL EVALUATION\n",
    "\n",
    "\n",
    "# INFERENCE\n",
    "# takes images of our labmates and classifies them\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[1;32m##################################################\u001b[0m] 100.0% ..Success (\u001b[1;32mCompleted: 10\u001b[0m, \u001b[1;33mQueued: 0\u001b[0m, \u001b[1;36mRunning: 0\u001b[0m, \u001b[1;31mFailed: 0\u001b[0m)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# add jobs to workflow\n",
    "wf.add_jobs(\n",
    "    preprocess_train_job,\n",
    "    distribution_plot_job\n",
    ")\n",
    "\n",
    "# run workflow\n",
    "try:\n",
    "    wf.plan(submit=True)\n",
    "    wf.wait()\n",
    "    wf.statistics()\n",
    "except PegasusClientError as e:\n",
    "    print(e.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
