{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/scitech/shared-data/mask-detection-workflow/img.png\n"
     ]
    }
   ],
   "source": [
    "# libraires for images and data\n",
    "from PIL import Image\n",
    "import glob,os\n",
    "from bs4 import BeautifulSoup\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "# libraries for deep learning\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets, models\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\n",
    "                                                                                                                                                                           \n",
    "import logging\n",
    "from Pegasus.api import *\n",
    "\n",
    "from utils.wf import split_data_filenames, create_ann_list,create_augmented_filelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When you restart the docker make sure to reinstall these:\n",
    "#! sudo python3 -m pip install --upgrade pip\n",
    "#! sudo python3 -m pip install --upgrade Pillow numpy torchvision matplotlib\n",
    "#! sudo python3 -m pip install pandas torch bs4\n",
    "\n",
    "#! sudo pip3 install opencv-python \n",
    "#! sudo pip3 install --upgrade setuptools\n",
    "#! sudo pip3 install opencv-python \n",
    "#! sudo pip3 install optuna==2.0.0 \n",
    "#! sudo pip3 install matplotlib \n",
    "#! sudo pip3 install torch\n",
    "#! sudo pip3 install scikit-image\n",
    "#! sudo pip3 install torchvision \n",
    "#! sudo pip3 install pytorchtools\n",
    "#! sudo pip3 install joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA AQUSITION\n",
    "imagesList = glob.glob('Images2/*.png')\n",
    "annotationList = glob.glob('annotations2/*.xml')\n",
    "\n",
    "#DATA SPLIT\n",
    "train_filenames,val_filenames,test_filenames, files_split_dict = split_data_filenames(imagesList)\n",
    "\n",
    "train_imgs, train_ann = create_ann_list(train_filenames)\n",
    "val_imgs, val_ann     = create_ann_list(val_filenames)\n",
    "test_imgs, test_ann   = create_ann_list(test_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rc = ReplicaCatalog()\n",
    "\n",
    "inputFiles = []\n",
    "for img in imagesList:\n",
    "    fileName = img.split(\"/\")[1]\n",
    "    img_file = File(fileName)\n",
    "    inputFiles.append(img_file)\n",
    "    rc.add_replica(\"local\", img_file,  os.path.join(os.getcwd(),str(img)))\n",
    "    \n",
    "annFiles = []\n",
    "for ann in annotationList:\n",
    "    fileName = ann.split(\"/\")[1]\n",
    "    ann_file = File(fileName)\n",
    "    annFiles.append(ann_file)\n",
    "    rc.add_replica(\"local\", ann_file,  os.path.join(os.getcwd(),str(ann)))\n",
    "rc.write()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'model_hpo = Transformation(\\n                \"hpo\",\\n                site=\"local\",\\n                pfn=  os.path.join(os.getcwd(),\"bin/model_hpo.py\"),\\n                is_stageable=True\\n            )'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add Transformations\n",
    "\n",
    "augment_imgs = Transformation(\n",
    "                \"augment_images\",\n",
    "                site=\"local\",\n",
    "                pfn=  os.path.join(os.getcwd(),\"bin/data_aug.py\"),\n",
    "                is_stageable=True\n",
    "            )\n",
    "\n",
    "\n",
    "'''model_hpo = Transformation(\n",
    "                \"hpo\",\n",
    "                site=\"local\",\n",
    "                pfn=  os.path.join(os.getcwd(),\"bin/model_hpo.py\"),\n",
    "                is_stageable=True\n",
    "            )'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tc = TransformationCatalog()\n",
    "tc.add_transformations(augment_imgs)#, model_hpo)\n",
    "tc.write()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocess_val_job = Job(preprocess_imgs)\n",
    "#preprocess_val_job.add_inputs(*val_imgs)\n",
    "#preprocess_val_job.add_outputs(*val_preprocessed_files)\n",
    "\n",
    "#val_preprocessed_files   = create_preprocessed_filelist(val_filenames)\n",
    "#test_preprocessed_files  = create_preprocessed_filelist(test_filenames)\n",
    "\n",
    "#preprocess_test_job = Job(preprocess_imgs)\n",
    "#preprocess_test_job.add_inputs(*test_imgs)\n",
    "#preprocess_test_job.add_outputs(*test_preprocessed_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Pegasus.api.workflow.Job at 0x7fd0fc34dba8>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create workflow\n",
    "\n",
    "wf = Workflow(\"mask_detection_workflow\")\n",
    "\n",
    "train_preprocessed_files = create_augmented_filelist(train_filenames,1)\n",
    "\n",
    "# Add jobs to the workflow\n",
    "\n",
    "\n",
    "# DATA EXPLORATION\n",
    "# takes in all the annotationa files and creates plot with distribution of the classes\n",
    "\n",
    "\n",
    "# DATA AUGMENTATION\n",
    "# takes images and adds gaussian noise to them\n",
    "preprocess_train_job = Job(augment_imgs)\n",
    "preprocess_train_job.add_inputs(*train_imgs)\n",
    "preprocess_train_job.add_outputs(*train_preprocessed_files)\n",
    "\n",
    "\n",
    "preprocess_val_job = Job(preprocess_imgs)\n",
    "preprocess_val_job.add_inputs(*val_imgs)\n",
    "preprocess_val_job.add_outputs(*val_preprocessed_files)\n",
    "\n",
    "\n",
    "preprocess_test_job = Job(preprocess_imgs)\n",
    "preprocess_test_job.add_inputs(*test_imgs)\n",
    "preprocess_test_job.add_outputs(*test_preprocessed_files)\n",
    "\n",
    "\n",
    "# HYPERPARAMETER OPTIMIZATION\n",
    "#hpo_job = Job(model_hpo)\n",
    "#hpo_job.add_inputs(*train_preprocessed_files, *val_preprocessed_files)\n",
    "#hpo_job.add_inputs(hpo_results)\n",
    "\n",
    "# MODEL TRAINING and EVALUATION\n",
    "\n",
    "\n",
    "# INFERENCE\n",
    "# takes images of our labmates and classifies them\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021.02.18 15:59:55.383 UTC:\n",
      "2021.02.18 15:59:55.388 UTC:   -----------------------------------------------------------------------\n",
      "2021.02.18 15:59:55.394 UTC:   File for submitting this DAG to HTCondor           : mask_detection_workflow-0.dag.condor.sub\n",
      "2021.02.18 15:59:55.399 UTC:   Log of DAGMan debugging messages                 : mask_detection_workflow-0.dag.dagman.out\n",
      "2021.02.18 15:59:55.404 UTC:   Log of HTCondor library output                     : mask_detection_workflow-0.dag.lib.out\n",
      "2021.02.18 15:59:55.409 UTC:   Log of HTCondor library error messages             : mask_detection_workflow-0.dag.lib.err\n",
      "2021.02.18 15:59:55.414 UTC:   Log of the life of condor_dagman itself          : mask_detection_workflow-0.dag.dagman.log\n",
      "2021.02.18 15:59:55.420 UTC:\n",
      "2021.02.18 15:59:55.425 UTC:   -no_submit given, not submitting DAG to HTCondor.  You can do this with:\n",
      "2021.02.18 15:59:55.435 UTC:   -----------------------------------------------------------------------\n",
      "2021.02.18 15:59:56.094 UTC:   Your database is compatible with Pegasus version: 5.1.0dev\n",
      "2021.02.18 15:59:56.859 UTC:   Created Pegasus database in: sqlite:////home/scitech/shared-data/mask-detection-workflow/scitech/pegasus/mask_detection_workflow/run0011/mask_detection_workflow-0.replicas.db\n",
      "2021.02.18 15:59:56.864 UTC:   Your database is compatible with Pegasus version: 5.1.0dev\n",
      "2021.02.18 15:59:56.917 UTC:   Output replica catalog set to jdbc:sqlite:/home/scitech/shared-data/mask-detection-workflow/scitech/pegasus/mask_detection_workflow/run0011/mask_detection_workflow-0.replicas.db\n",
      "[WARNING]  Submitting to condor mask_detection_workflow-0.dag.condor.sub\n",
      "2021.02.18 15:59:57.368 UTC:   Time taken to execute is 2.355 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[1;32m####################################\u001b[0m] 100.0% ..Success (\u001b[1;32mCompleted: 9\u001b[0m, \u001b[1;33mQueued: 0\u001b[0m, \u001b[1;36mRunning: 0\u001b[0m, \u001b[1;31mFailed: 0\u001b[0m)\n"
     ]
    }
   ],
   "source": [
    "# add jobs to workflow\n",
    "wf.add_jobs(\n",
    "    preprocess_train_job,\n",
    ")\n",
    "\n",
    "# run workflow\n",
    "try:\n",
    "    wf.plan(submit=True)\n",
    "    wf.wait()\n",
    "    wf.statistics()\n",
    "except PegasusClientError as e:\n",
    "    print(e.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
