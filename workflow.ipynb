{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/scitech/shared-data/face-recognition-wf/img.png\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import glob,os\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets, models\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "import os                                                                                                                                                                               \n",
    "import logging\n",
    "from Pegasus.api import *\n",
    "\n",
    "\n",
    "from utils.wf import split_data_filenames, create_ann_list, create_preprocessed_filelist\n",
    "\n",
    "# use this to get path to your current dir and get absolute paths to your files\n",
    "filename = \"img.png\"\n",
    "print(os.path.join(os.getcwd(),filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# When you restart the docker make sure to reinstall these:\n",
    "#! sudo python3 -m pip install --upgrade pip\n",
    "#! sudo python3 -m pip install --upgrade Pillow numpy torchvision matplotlib\n",
    "#! sudo python3 -m pip install pandas torch bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagesList = glob.glob('Images2/*.png')\n",
    "annotationList = glob.glob('annotations2/*.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_filenames,val_filenames,test_filenames, files_split_dict = split_data_filenames(imagesList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_imgs, train_ann = create_ann_list(train_filenames)\n",
    "val_imgs, val_ann     = create_ann_list(val_filenames)\n",
    "test_imgs, test_ann   = create_ann_list(test_filenames)\n",
    "\n",
    "train_preprocessed_files = create_preprocessed_filelist(train_filenames)\n",
    "val_preprocessed_files   = create_preprocessed_filelist(val_filenames)\n",
    "test_preprocessed_files  = create_preprocessed_filelist(test_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "rc = ReplicaCatalog()\n",
    "\n",
    "inputFiles = []\n",
    "for img in imagesList:\n",
    "    fileName = img.split(\"/\")[1]\n",
    "    img_file = File(fileName)\n",
    "    inputFiles.append(img_file)\n",
    "    rc.add_replica(\"local\", img_file,  os.path.join(os.getcwd(),str(img)))\n",
    "    \n",
    "annFiles = []\n",
    "for ann in annotationList:\n",
    "    fileName = ann.split(\"/\")[1]\n",
    "    ann_file = File(fileName)\n",
    "    annFiles.append(ann_file)\n",
    "    rc.add_replica(\"local\", ann_file,  os.path.join(os.getcwd(),str(ann)))\n",
    "rc.write()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'model_hpo = Transformation(\\n                \"hpo\",\\n                site=\"local\",\\n                pfn=  os.path.join(os.getcwd(),\"bin/model_hpo.py\"),\\n                is_stageable=True\\n            )'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add Transformations\n",
    "\n",
    "preprocess_imgs = Transformation(\n",
    "                \"preprocess_images\",\n",
    "                site=\"local\",\n",
    "                pfn=  os.path.join(os.getcwd(),\"bin/img_norm.py\"),\n",
    "                is_stageable=True\n",
    "            )\n",
    "\n",
    "\n",
    "'''model_hpo = Transformation(\n",
    "                \"hpo\",\n",
    "                site=\"local\",\n",
    "                pfn=  os.path.join(os.getcwd(),\"bin/model_hpo.py\"),\n",
    "                is_stageable=True\n",
    "            )'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tc = TransformationCatalog()\n",
    "tc.add_transformations(preprocess_imgs)#, model_hpo)\n",
    "tc.write()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Pegasus.api.workflow.Job at 0x7f562c88a940>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create workflow\n",
    "\n",
    "wf = Workflow(\"mask_detection_workflow\")\n",
    "\n",
    "\n",
    "# Add jobs to the workflow\n",
    "\n",
    "preprocess_train_job = Job(preprocess_imgs)\n",
    "preprocess_train_job.add_inputs(*train_imgs)\n",
    "preprocess_train_job.add_outputs(*train_preprocessed_files)\n",
    "\n",
    "\n",
    "preprocess_val_job = Job(preprocess_imgs)\n",
    "preprocess_val_job.add_inputs(*val_imgs)\n",
    "preprocess_val_job.add_outputs(*val_preprocessed_files)\n",
    "\n",
    "\n",
    "preprocess_test_job = Job(preprocess_imgs)\n",
    "preprocess_test_job.add_inputs(*test_imgs)\n",
    "preprocess_test_job.add_outputs(*test_preprocessed_files)\n",
    "\n",
    "\n",
    "#hpo_job = Job(model_hpo)\n",
    "#hpo_job.add_inputs(*train_preprocessed_files, *val_preprocessed_files)\n",
    "#hpo_job.add_inputs(hpo_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[1;32m##################################################\u001b[0m] 100.0% ..Success (\u001b[1;32mCompleted: 11\u001b[0m, \u001b[1;33mQueued: 0\u001b[0m, \u001b[1;36mRunning: 0\u001b[0m, \u001b[1;31mFailed: 0\u001b[0m)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# add jobs to workflow\n",
    "wf.add_jobs(\n",
    "    preprocess_train_job,\n",
    "    preprocess_val_job,\n",
    "    preprocess_test_job\n",
    ")\n",
    "\n",
    "# run workflow\n",
    "try:\n",
    "    wf.plan(submit=True)\n",
    "    wf.wait()\n",
    "    wf.statistics()\n",
    "except PegasusClientError as e:\n",
    "    print(e.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
